{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5f45b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install optuna hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030e05ff",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c40e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV, RepeatedKFold\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from optuna import create_study\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.integration import XGBoostPruningCallback\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60be321",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c601bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('../asset/train_df.pkl')\n",
    "test_df = pd.read_pickle('../asset/test_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f8e43d",
   "metadata": {},
   "source": [
    "### Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8af2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_all_features(data):\n",
    "    \n",
    "    \"\"\"This function will help us to convert boolean and cateogrical values to numerical values.\n",
    "    \n",
    "    Input:\n",
    "    data -> dataframe (the original dataframe)\n",
    "    \n",
    "    Output:\n",
    "    final_df -> dataframe (after feature conversions including one hot encoding and ordinal encoding)\n",
    "    \"\"\"\n",
    "    \n",
    "    # selecting features that we will use for the Prophet model\n",
    "    features = list(data.columns)\n",
    "    \n",
    "    # treat train and test dataset in a different way\n",
    "    if 'sales' in data.columns:\n",
    "        features.append('sales')\n",
    "        \n",
    "    oe = OrdinalEncoder()\n",
    "\n",
    "    not_transformed = []\n",
    "    no_need_to_transform = []\n",
    "    \n",
    "    \n",
    "    # based on the features, use different methods for encoders. \n",
    "    for col, dtype in data.dtypes.items():\n",
    "        if col in ['date', 'unique_key', 'date_year', 'date_quarter', 'date_month', 'date_day', 'date_week', 'year_month'] or dtype in ['datetime64[ns]', 'timedelta64[ns]']:\n",
    "            no_need_to_transform.append(col)\n",
    "        elif col == 'transferred':\n",
    "            data.loc[:, col] = data[col].apply(lambda x: 1 if x == True else 0)\n",
    "        elif col in ['state_sales_cut', 'store_sales_bins', 'store_type_sales',\n",
    "                     'family_sales_bins', 'onpromo_avg_bins', 'cluster_sales_indicator']:\n",
    "            data.loc[:, col] = oe.fit_transform(data[col].values.reshape(-1,1))\n",
    "        else:\n",
    "            not_transformed.append(col) \n",
    "    dummy_df = pd.get_dummies(data.drop(columns = no_need_to_transform))\n",
    "    return dummy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb10486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_split(data, train_size):\n",
    "    \n",
    "    \"\"\"This function will help us create train test split in time series.\n",
    "    \n",
    "    Input:\n",
    "    data -> dataframe (the original dataframe)\n",
    "    train_size -> float (the percentage of train_set in our dataset)\n",
    "    \n",
    "    Output:\n",
    "    train_df -> dataframe (train_set based on the train_size)\n",
    "    test_df -> dataframe (test_set based on the train_size)\"\"\"\n",
    "    \n",
    "    total_row = len(data)\n",
    "    train_idx = int(total_row * train_size)\n",
    "    \n",
    "    train = data[:train_idx]\n",
    "    test = data[train_idx:]\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd6a59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_errors(pred_dict, actual, yhat):\n",
    "    \n",
    "    \"\"\"This function will calculate the erorrs using mean absolute erorrs.\n",
    "    \n",
    "    Input:\n",
    "    pred_dict -> dict (key: unique_key, values: y and yhat)\n",
    "    actual -> (values: the actual y value)\n",
    "    yhat -> (values: the predicdted value from the model)\n",
    "    \n",
    "    Output:\n",
    "    error -> int (mean absolute erorr)\"\"\"\n",
    "    \n",
    "\n",
    "    \n",
    "    error_total = 0\n",
    "    # looping through the dictionary and summing the error.\n",
    "    for key in pred_dict:\n",
    "        error = mean_absolute_error(pred_dict[key][actual], pred_dict[key][yhat])\n",
    "        error_total += error\n",
    "        \n",
    "    return error_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b502099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(original_df, analyze_df):\n",
    "    \n",
    "    \"\"\"This function will look into different predictions and their original distribtuion.\n",
    "    \n",
    "    Input:\n",
    "    origianl_df -> dataframe (original dataframe before the training)\n",
    "    analyze_df -> dataframe (dataframe that has information regarding prediction)\n",
    "    \n",
    "    Output:\n",
    "    summary_df -> series (shows the summary statistics for the given stores and departments)\"\"\"\n",
    "    \n",
    "    key_lists = list(analyze_df['unique_key'])\n",
    "    \n",
    "    for key in key_lists:\n",
    "        data = original_df[original_df.unique_str_dep_key == key]\n",
    "        sales_only = data['sales']\n",
    "        \n",
    "        print(f\"Summary Statistics for {key}:\")\n",
    "        print(sales_only.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92683d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_info(train_dict, test_dict):\n",
    "    \n",
    "    \"\"\"This function will return a combination of y and y hat including dates from the XGBoost model.\n",
    "       \n",
    "       Input:\n",
    "       \n",
    "       train_dict -> dictionary (contains information regarding date, y and y hat)\n",
    "       test_dict -> dictionary (contains information regarding date, y and y hat)\n",
    "       \n",
    "       Output:\n",
    "       \n",
    "       combined_df -> dataframe (contains information from the both datasets)\"\"\"\n",
    "    \n",
    "    # create a dictionary to save the results\n",
    "    combined_df = pd.DataFrame()\n",
    "    \n",
    "    # looping through\n",
    "    for key in train_dict:\n",
    "        # create temporary dataframes for both train and test\n",
    "        # also create a column to indicate if they come from the training set or test set.\n",
    "        train = pd.DataFrame(train_dict[key])\n",
    "        train.loc[:,'ind'] = 'train'\n",
    "        test = pd.DataFrame(test_dict[key])\n",
    "        test.loc[:,'ind'] = 'test'\n",
    "        total_df = pd.concat([train, test])\n",
    "        \n",
    "        # combine the dataframes together\n",
    "        combined_df = combined_df.append(total_df, ignore_index= True)\n",
    "        \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9846d31",
   "metadata": {},
   "source": [
    "### Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99246c8",
   "metadata": {},
   "source": [
    "- filter out zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005832d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "space={'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
    "        'gamma': hp.uniform ('gamma', 1, 9),\n",
    "        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'n_estimators': hp.quniform('n_estimators', 100, 600, 50),\n",
    "        'seed': 42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53eb6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    \n",
    "    clf=XGBRegressor(\n",
    "                    n_estimators =int(space['n_estimators']), max_depth = int(space['max_depth']), gamma = space['gamma'],\n",
    "                    reg_alpha = int(space['reg_alpha']),min_child_weight=int(space['min_child_weight']),\n",
    "                    colsample_bytree=int(space['colsample_bytree']),\n",
    "                    n_jobs = 16)\n",
    "    \n",
    "    evaluation = [( train_X, train_y), ( test_X, test_y)]\n",
    "    \n",
    "    clf.fit(train_X, \n",
    "            train_y,\n",
    "            eval_set=evaluation, \n",
    "            eval_metric=\"rmse\",\n",
    "            early_stopping_rounds=10,\n",
    "            verbose=False)\n",
    "    \n",
    "\n",
    "    pred = clf.predict(test_X)\n",
    "    rmse = np.sqrt(mean_squared_error(test_y, pred))\n",
    "    \n",
    "    print (\"SCORE:\", rmse)\n",
    "    return {'loss': rmse, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832b47c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# define space\n",
    "space={'max_depth': hp.quniform(\"max_depth\", 2, 20, 1),\n",
    "        'gamma': hp.uniform ('gamma', 1, 7),\n",
    "        'reg_alpha' : hp.quniform('reg_alpha', 20, 180, 1),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0, 1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5, 1),\n",
    "        'subsample'        :hp.uniform('subsample', 0.5, 1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 1, 12, 1),\n",
    "        'n_estimators': hp.quniform('n_estimators', 100, 600, 30),\n",
    "        'seed': 42\n",
    "    }\n",
    "\n",
    "# change the name \n",
    "# causes an issue when saving the parameters, so change the special character / to &\n",
    "train_df.loc[:, 'family'] = train_df.family.apply(lambda x: str(x).replace('/', '&'))\n",
    "\n",
    "# create dictionaries to save the results\n",
    "xgb_params_dict = {}\n",
    "\n",
    "# create unique keys based on the store number and departments\n",
    "train_df.loc[:, 'unique_str_dep_key'] = train_df.store_nbr.apply(lambda x: str(x)) + '-' + train_df.family.apply(lambda x: str(x))\n",
    "\n",
    "# get the unique list of keys\n",
    "unique_key_list = list(train_df.unique_str_dep_key.unique())\n",
    "\n",
    "# filter stores that have 0 sales\n",
    "total_sales_df = train_df.groupby('unique_str_dep_key').sum()[['sales']]\n",
    "zero_sales = total_sales_df[total_sales_df.sales == 0]\n",
    "\n",
    "# find stores that have zero sales total\n",
    "zero_list = list(zero_sales.index)\n",
    "\n",
    "# we want to filter out data based on the unique keys\n",
    "for key in unique_key_list:\n",
    "    \n",
    "    if key not in zero_list:\n",
    "        # filter out data\n",
    "        data = train_df[train_df.unique_str_dep_key == key]\n",
    "        data.reset_index().drop(columns = ['index', 'date', 'store_nbr', 'family'])\n",
    "\n",
    "        # perform feature engineering -> one hot coding\n",
    "        new_data = convert_all_features(data)\n",
    "\n",
    "        # train test split (70:30)\n",
    "        train, test = time_split(new_data, 0.7)\n",
    "        train.drop_duplicates(inplace = True)\n",
    "        test.drop_duplicates(inplace = True)\n",
    "\n",
    "        # assign predictors and target variables\n",
    "        train_X, train_y = train.drop(columns = ['sales']), train.sales.values\n",
    "        test_X, test_y = test.drop(columns = ['sales']), test.sales.values\n",
    "        \n",
    "        \n",
    "        trials = Trials()\n",
    "        best_hyperparams = fmin(fn = objective,\n",
    "                                space = space,\n",
    "                                algo = tpe.suggest,\n",
    "                                max_evals = 100,\n",
    "                                trials = trials)\n",
    "        \n",
    "        print(f\"{key} found best params.\")\n",
    "        # save the best results\n",
    "        xgb_params_dict[key] = best_hyperparams\n",
    "        \n",
    "        # save the best results as pickle objects\n",
    "        with open(f'../asset/best_params_optuna/best_params_{key}.pkl', 'wb') as f:\n",
    "            pickle.dump(xgb_params_dict[key], f)\n",
    "        \n",
    "    else:\n",
    "        # meaning these store + dep combinations have 0 sales\n",
    "        xgb_params_dict[key] = 'zero_coef'\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625c146d",
   "metadata": {},
   "source": [
    "- change the data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26da229",
   "metadata": {},
   "outputs": [],
   "source": [
    "for u_key in xgb_params_dict:\n",
    "    if isinstance(xgb_params_dict[u_key], str):\n",
    "        pass\n",
    "    else:\n",
    "        for key, val in xgb_params_dict[u_key].items():\n",
    "            if key in ['max_depth', 'min_child_weight', 'n_estimators']:\n",
    "                xgb_params_dict[u_key][key] = int(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce6b060",
   "metadata": {},
   "source": [
    "### Use hyper parameters in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5101db",
   "metadata": {},
   "source": [
    "actual and y hat are the issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c58cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionaries to save the results\n",
    "xgb_pred_dict_train = {}\n",
    "xgb_pred_dict_test = {}\n",
    "\n",
    "# loop through the unique key\n",
    "for u_key in xgb_params_dict:\n",
    "    \n",
    "    # filter dataframe so that we can only get the unique df\n",
    "    data = train_df[train_df.unique_str_dep_key == u_key]\n",
    "    total_row = len(data)\n",
    "    train_idx = int(0.7 * total_row)\n",
    "    \n",
    "    data.reset_index().drop(columns = ['index', 'date', 'store_nbr', 'family'])\n",
    "\n",
    "    # perform feature engineering -> one hot coding\n",
    "    new_data = convert_all_features(data)\n",
    "\n",
    "    # train test split (70:30)\n",
    "    train, test = time_split(new_data, 0.7)\n",
    "    train.drop_duplicates(inplace = True)\n",
    "    test.drop_duplicates(inplace = True)\n",
    "    \n",
    "    # assign predictors and target variables\n",
    "    train_X, train_y = train.drop(columns = ['sales']), train.sales.values\n",
    "    test_X, test_y = test.drop(columns = ['sales']), test.sales.values\n",
    "    \n",
    "    # if values == zero_coef, then pass\n",
    "    if isinstance(xgb_params_dict[u_key], str):\n",
    "        pass\n",
    "    else:\n",
    "        # if values inside the params dict are not zero_coef, then used the best hyper params to train the model\n",
    "        best_params = xgb_params_dict[u_key]\n",
    "        xgbr = XGBRegressor(**best_params)\n",
    "        xgbr.fit(train_X, train_y)\n",
    "        \n",
    "        train_y_hat = xgbr.predict(train_X)\n",
    "        test_y_hat = xgbr.predict(test_X)\n",
    "        \n",
    "        # save the results based on traning and validation\n",
    "        xgb_pred_dict_train[u_key] = {'actual':train_y,\n",
    "                                      'yhat':train_y_hat}\n",
    "        \n",
    "        xgb_pred_dict_test[u_key] = {'actual':test_y,\n",
    "                                     'yhat':test_y_hat}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d7a320",
   "metadata": {},
   "source": [
    "Combine the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df9a0cf",
   "metadata": {},
   "source": [
    "Find the total error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808882d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "\n",
    "for key in xgb_pred_dict_test:\n",
    "    error = mean_absolute_error(xgb_pred_dict_test[key]['actual'], xgb_pred_dict_test[key]['yhat'])\n",
    "    total += error\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dff130",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_dict = {}\n",
    "\n",
    "for key in xgb_pred_dict_test:\n",
    "    error_dict[key] = mean_absolute_error(xgb_pred_dict_test[key]['actual'], xgb_pred_dict_test[key]['yhat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ece456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_test_error_df = pd.DataFrame(error_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276a313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_test_error_df.columns = ['unique_key', 'mae']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe96498",
   "metadata": {},
   "source": [
    "Look into individual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0683a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_worst = xgb_test_error_df.sort_values(by = 'mae', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016afe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_best = xgb_test_error_df[xgb_test_error_df.mae != 0].sort_values(by = 'mae').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858bf04b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analyze_results(train_df, top10_worst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4285722",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analyze_results(train_df, top10_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2427296",
   "metadata": {},
   "source": [
    "Looking at the summary stats, best top 10 has the lowest mean and standard deviation, while the top 10 worst has relatively higher means and standard deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974bb241",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b937ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_list = list(top10_worst.unique_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5174b83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_list = list(top10_best.unique_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc699aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(datelist) + timedelta(days = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb79301",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.DataFrame()\n",
    "start_date = pd.to_datetime('2013-01-01')\n",
    "\n",
    "for key in xgb_pred_dict_test:\n",
    "    # if unique key in either best or worst, let's take a look\n",
    "    \n",
    "    if key in worst_list or key in best_list:\n",
    "        train = pd.DataFrame(xgb_pred_dict_train[key])\n",
    "        train.loc[:, 'ind'] = 'train'\n",
    "        train.loc[:, 'unique_key'] = key\n",
    "        \n",
    "        test = pd.DataFrame(xgb_pred_dict_test[key])\n",
    "        test.loc[:, 'ind'] = 'test'\n",
    "        test.loc[:, 'unique_key'] = key\n",
    "        \n",
    "        train_datelist = pd.date_range(start_date, periods=len(xgb_pred_dict_train[key]['actual'])).tolist()\n",
    "        train.loc[:, 'date'] = train_datelist\n",
    "\n",
    "        test_start_date = max(datelist) + timedelta(days = 1)\n",
    "        test_datelist = pd.date_range(test_start_date, periods= len(xgb_pred_dict_test[key]['actual'])).tolist()\n",
    "        test.loc[:, 'date'] = test_datelist\n",
    "        \n",
    "        # combine datasets together\n",
    "        total = pd.concat([train,test])\n",
    "        combined_df = combined_df.append(total, ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582cda51",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.loc[:, 'which_list'] = combined_df.apply(lambda row: 'best' if row['unique_key'] in best_list else 'worst', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd04e5a",
   "metadata": {},
   "source": [
    "Best Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad478aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_name =  '../asset/plots/best_xgb_forecasts.pdf'\n",
    "pp = PdfPages(plot_name)\n",
    "\n",
    "for key in best_list:\n",
    "    \n",
    "    # filter out data\n",
    "    data = combined_df[combined_df.unique_key == key]\n",
    "    plt.figure(figsize = (12, 8))\n",
    "    plt.title(f\"Analyze Predictions for {key}\", fontsize = 18)\n",
    "    \n",
    "    sns.lineplot(x = 'date',\n",
    "                 y = 'actual',\n",
    "                 color = 'grey',\n",
    "                 alpha = 0.7,\n",
    "                 data = data,\n",
    "                 label = 'actual')\n",
    "    \n",
    "    sns.lineplot(x = 'date',\n",
    "                 y = 'yhat',\n",
    "                 color = 'blue',\n",
    "                 alpha = 0.7,\n",
    "                 data = data[data.ind == 'train'],\n",
    "                 label = 'train')\n",
    "    \n",
    "    sns.lineplot(x = 'date',\n",
    "                 y = 'yhat',\n",
    "                 color = 'red',\n",
    "                 alpha = 0.7,\n",
    "                 data = data[data.ind == 'test'],\n",
    "                 label = 'test')\n",
    "    sns.despine()\n",
    "    plt.legend()\n",
    "    pp.savefig(plt.gcf())           \n",
    "\n",
    "\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecf76e6",
   "metadata": {},
   "source": [
    "Worst Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f6ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_name =  '../asset/plots/worst_xgb_forecasts.pdf'\n",
    "pp = PdfPages(plot_name)\n",
    "\n",
    "for key in worst_list:\n",
    "    \n",
    "    # filter out data\n",
    "    data = combined_df[combined_df.unique_key == key]\n",
    "    plt.figure(figsize = (12, 8))\n",
    "    plt.title(f\"Analyze Predictions for {key}\", fontsize = 18)\n",
    "    \n",
    "    sns.lineplot(x = 'date',\n",
    "                 y = 'actual',\n",
    "                 color = 'grey',\n",
    "                 alpha = 0.9,\n",
    "                 data = data,\n",
    "                 label = 'actual')\n",
    "    \n",
    "    sns.lineplot(x = 'date',\n",
    "                 y = 'yhat',\n",
    "                 color = 'blue',\n",
    "                 alpha = 0.5,\n",
    "                 data = data[data.ind == 'train'],\n",
    "                 label = 'train')\n",
    "    \n",
    "    sns.lineplot(x = 'date',\n",
    "                 y = 'yhat',\n",
    "                 color = 'red',\n",
    "                 alpha = 0.5,\n",
    "                 data = data[data.ind == 'test'],\n",
    "                 label = 'test')\n",
    "    sns.despine()\n",
    "    plt.legend()\n",
    "    pp.savefig(plt.gcf())           \n",
    "\n",
    "\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e3cfa1",
   "metadata": {},
   "source": [
    "Although the errors seem to be huge in the worst prediction list, our test prediction did not seem to be that bad. The reason why we have good results on the best_list is that most of the times the sales in those departments were relatively low, but they seem to have seasonal operations. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
